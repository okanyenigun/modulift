{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okanyenigun/Desktop/codes/reals/pypi_pkgs/v1/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import modulift as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'package': 'numpy', 'description': 'NumPy is the fundamental package for scientific computing with Python. It provides powerful N-dimensional arrays, sophisticated mathematical functions, tools for integrating C/C++ and Fortran code, and useful linear algebra, Fourier transform, and random number capabilities.', 'keywords': 'scientific computing, array, linear algebra, Fourier transform, random number generation, data processing, numerical analysis', 'popularity': 5}\n"
     ]
    }
   ],
   "source": [
    "result = mf.search_by_package_name(\"numpy\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'package': 'nullsweep', 'description': 'NullSweep is a Python library designed for detecting and handling patterns of missing data in pandas DataFrames. It provides a simple API to identify global missing data patterns across the entire dataset, patterns related to specific features within the dataset, and to impute missing values using various strategies.', 'keywords': 'missing data, data imputation, pandas, pattern detection, feature-specific patterns', 'popularity': 4}\n"
     ]
    }
   ],
   "source": [
    "result = mf.search_by_package_name(\"nullsweep\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**numpy**\n",
       "\n",
       "- **Description**: NumPy is the fundamental package for scientific computing with Python. It provides powerful N-dimensional arrays, sophisticated mathematical functions, tools for integrating C/C++ and Fortran code, and useful linear algebra, Fourier transform, and random number capabilities.\n",
       "- **Keywords**: scientific computing, array, linear algebra, Fourier transform, random number generation, data processing, numerical analysis\n",
       "- **Popularity**: 5\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = mf.search_by_package_name(\"numpy\", markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3111\n"
     ]
    }
   ],
   "source": [
    "result = mf.search_by_keywords(\"data science\")\n",
    "\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "result = mf.search_by_keywords(\"data science\", \"machine learning\", \"deep learning\", relation=\"and\")\n",
    "\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**neuralhydrology**\n",
       "\n",
       "- **Description**: A Python library for training neural networks with a focus on hydrological applications.\n",
       "- **Keywords**: machine learning, deep learning, hydrology, water resources, data science\n",
       "- **Popularity**: 5\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**sktutor**\n",
       "\n",
       "- **Description**: A Python library designed to facilitate machine learning tasks, enabling users to build and train models for various applications.\n",
       "- **Keywords**: machine learning, data science, deep learning\n",
       "- **Popularity**: 5\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**libro-ai**\n",
       "\n",
       "- **Description**: A Python library for building and deploying AI models. It provides tools for data preprocessing, model training, and evaluation.\n",
       "- **Keywords**: machine learning, AI, deep learning, data science, model development\n",
       "- **Popularity**: 5\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "result = mf.search_by_keywords(\"data science\", \"machine learning\", \"deep learning\", relation=\"and\", limit=3, markdown=True)\n",
    "\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**sagemaker**\n",
       "\n",
       "- **Description**: The SageMaker Python SDK is an open-source library designed for training and deploying machine learning models on Amazon SageMaker. It supports popular deep learning frameworks like Apache MXNet and TensorFlow, as well as Amazon's own scalable algorithms optimized for SageMaker. Users can also deploy custom algorithms in Docker containers, making it versatile for various machine learning tasks.\n",
       "- **Keywords**: machine learning, deep learning, model deployment, Amazon SageMaker, data science, AI, Docker\n",
       "- **Popularity**: 5\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = mf.search_by_description(\"training and deploying machine learning models on Amazon\", markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
